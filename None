# ==============================
# CELL 1 ‚Äì SETTINGS & WIDGETS
# ==============================
import ipywidgets as widgets
from IPython.display import display

print("üîß Bubble Grader Settings\n")

# ---- Listening Answer Key (10 questions) ----
listening_inputs = [widgets.Text(value="", description=f"L{i+1}") for i in range(10)]
listening_box = widgets.VBox([
    widgets.HTML("<b>Listening Answer Key (A‚ÄìE). Use 0 or leave blank to IGNORE a question:</b>"),
    *listening_inputs
])

# ---- Structure Answer Key (20 questions) ----
structure_inputs = [widgets.Text(value="", description=f"S{i+1}") for i in range(20)]
structure_box = widgets.VBox([
    widgets.HTML("<b>Structure Answer Key (A‚ÄìD):</b>"),
    *structure_inputs
])

# ---- Reading Answer Key (10 questions) ----
reading_inputs = [widgets.Text(value="", description=f"R{i+1}") for i in range(10)]
reading_box = widgets.VBox([
    widgets.HTML("<b>Reading Answer Key (A‚ÄìD). Use 0 or leave blank to IGNORE:</b>"),
    *reading_inputs
])

# ---- Point Values per Question ----
points_listening = widgets.FloatText(value=1.0, description="Listening per Q")
points_structure = widgets.FloatText(value=1.5, description="Structure per Q")
points_reading = widgets.FloatText(value=1.0, description="Reading per Q")

points_box = widgets.VBox([
    widgets.HTML("<b>Point Values (per question):</b>"),
    points_listening,
    points_structure,
    points_reading
])

display(listening_box, structure_box, reading_box, points_box)

print("\nüëâ Fill in the answer keys and point values above.")
print("   When you're ready, run the NEXT CELL to lock them in and start grading.")


# ==============================
# CELL 2 ‚Äì BUBBLE GRADING SCRIPT
# ==============================
import cv2
import numpy as np
import os
import csv
from google.colab import files
import shutil

# ---- Ensure settings from Cell 1 exist ----
if 'listening_inputs' not in globals() or 'points_listening' not in globals():
    raise RuntimeError("‚ö†Ô∏è Please run CELL 1 first to set up the widgets.")

# ====== CAPTURE SETTINGS FROM WIDGETS ======

def capture_answer_key():
    listening_key = {f"Q{i+1}": listening_inputs[i].value.upper().strip() for i in range(10)}
    structure_key = {f"Q{i+1}": structure_inputs[i].value.upper().strip() for i in range(20)}
    reading_key   = {f"Q{i+1}": reading_inputs[i].value.upper().strip() for i in range(10)}

    # Empty entries become "0" (ignored)
    for key_dict in (listening_key, structure_key, reading_key):
        for k, v in key_dict.items():
            if v == "":
                key_dict[k] = "0"   # 0 = ignore this question

    return {
        "listening": listening_key,
        "structure": structure_key,
        "reading": reading_key
    }

ANSWER_KEY = capture_answer_key()

POINTS = {
    "listening": float(points_listening.value),
    "structure": float(points_structure.value),
    "reading": float(points_reading.value)
}

MAX_POINTS = {
    "listening": POINTS["listening"] * 10,  # 10 listening questions
    "structure": POINTS["structure"] * 20,  # 20 structure questions
    "reading": POINTS["reading"] * 10       # 10 reading questions
}

print("‚úÖ Settings locked in:")
print("LISTENING KEY:", ANSWER_KEY["listening"])
print("STRUCTURE KEY:", ANSWER_KEY["structure"])
print("READING KEY:", ANSWER_KEY["reading"])
print("POINTS:", POINTS)
print("MAX POINTS:", MAX_POINTS)

# ==============================
# FILE / FOLDER SETUP
# ==============================

TEST_FOLDER = "colab_test_images"
RESULT_FOLDER = "colab_results"
os.makedirs(TEST_FOLDER, exist_ok=True)
os.makedirs(RESULT_FOLDER, exist_ok=True)

BUBBLE_GRADING_CSV = os.path.join(RESULT_FOLDER, "bubble_grading_results.csv")

TEMPLATE_SIZE = (2550, 3300)
RADIUS = 20
CONFIDENCE_GAP = 10

TEXT_POSITIONS = {
    'listening_score_box': (650, 2595),
    'structure_score_box': (910, 2595),
    'reading_score_box':   (1170, 2595),
}

OFFSETS = {
    'listening': (0, 0),
    'structure': (0, 0),
    'reading':   (0, 0)
}

# ==============================
# BUBBLE COORDINATES
# ==============================

listening_bubbles = {
    'Q1':  {'A': (197, 956),  'B': (283, 956),  'C': (379, 956),  'D': (468, 956),  'E': (554, 956)},
    'Q2':  {'A': (197, 1016), 'B': (286, 1016), 'C': (379, 1016), 'D': (465, 1016), 'E': (557, 1016)},
    'Q3':  {'A': (197, 1074), 'B': (286, 1071), 'C': (376, 1074), 'D': (468, 1074), 'E': (554, 1074)},
    'Q4':  {'A': (197, 1128), 'B': (286, 1128), 'C': (379, 1128), 'D': (468, 1128), 'E': (557, 1128)},
    'Q5':  {'A': (197, 1188), 'B': (286, 1182), 'C': (376, 1188), 'D': (465, 1185), 'E': (557, 1188)},
    'Q6':  {'A': (194, 1246), 'B': (286, 1243), 'C': (376, 1249), 'D': (465, 1249), 'E': (554, 1246)},
    'Q7':  {'A': (197, 1300), 'B': (290, 1297), 'C': (372, 1303), 'D': (465, 1303), 'E': (554, 1303)},
    'Q8':  {'A': (197, 1361), 'B': (290, 1361), 'C': (376, 1361), 'D': (468, 1361), 'E': (554, 1361)},
    'Q9':  {'A': (197, 1415), 'B': (286, 1412), 'C': (376, 1415), 'D': (465, 1418), 'E': (554, 1418)},
    'Q10': {'A': (197, 1475), 'B': (286, 1472), 'C': (376, 1475), 'D': (465, 1475), 'E': (554, 1475)}
}

structure_bubbles = {
    'Q1':  {'A': (1029, 956), 'B': (1115, 956), 'C': (1204, 959), 'D': (1294, 962)},
    'Q2':  {'A': (1029, 1020),'B': (1115, 1016),'C': (1204, 1020),'D': (1294, 1020)},
    'Q3':  {'A': (1026, 1077),'B': (1115, 1074),'C': (1204, 1077),'D': (1294, 1077)},
    'Q4':  {'A': (1026, 1134),'B': (1115, 1131),'C': (1204, 1134),'D': (1294, 1134)},
    'Q5':  {'A': (1026, 1198),'B': (1112, 1192),'C': (1204, 1195),'D': (1294, 1192)},
    'Q6':  {'A': (1026, 1252),'B': (1115, 1249),'C': (1201, 1252),'D': (1294, 1252)},
    'Q7':  {'A': (1026, 1310),'B': (1115, 1310),'C': (1204, 1310),'D': (1294, 1310)},
    'Q8':  {'A': (1026, 1367),'B': (1115, 1367),'C': (1201, 1367),'D': (1290, 1367)},
    'Q9':  {'A': (1026, 1428),'B': (1115, 1421),'C': (1201, 1424),'D': (1294, 1424)},
    'Q10': {'A': (1026, 1485),'B': (1112, 1482),'C': (1204, 1482),'D': (1290, 1482)},
    'Q11': {'A': (1026, 1542),'B': (1115, 1542),'C': (1204, 1542),'D': (1290, 1542)},
    'Q12': {'A': (1026, 1600),'B': (1115, 1596),'C': (1204, 1600),'D': (1294, 1596)},
    'Q13': {'A': (1026, 1660),'B': (1115, 1657),'C': (1201, 1660),'D': (1294, 1660)},
    'Q14': {'A': (1026, 1718),'B': (1115, 1718),'C': (1201, 1718),'D': (1294, 1718)},
    'Q15': {'A': (1026, 1775),'B': (1115, 1775),'C': (1204, 1775),'D': (1294, 1775)},
    'Q16': {'A': (1023, 1836),'B': (1118, 1832),'C': (1204, 1832),'D': (1290, 1832)},
    'Q17': {'A': (1026, 1893),'B': (1115, 1890),'C': (1204, 1893),'D': (1294, 1893)},
    'Q18': {'A': (1026, 1953),'B': (1115, 1947),'C': (1201, 1953),'D': (1294, 1953)},
    'Q19': {'A': (1026, 2014),'B': (1118, 2008),'C': (1204, 2008),'D': (1294, 2011)},
    'Q20': {'A': (1026, 2068),'B': (1112, 2068),'C': (1204, 2068),'D': (1294, 2068)}
}

reading_bubbles = {
    'Q1':  {'A': (1855, 959),  'B': (1947, 959),  'C': (2036, 959),  'D': (2129, 959)},
    'Q2':  {'A': (1855, 1020), 'B': (1947, 1020), 'C': (2036, 1020), 'D': (2132, 1020)},
    'Q3':  {'A': (1858, 1074), 'B': (1944, 1074), 'C': (2036, 1077), 'D': (2129, 1080)},
    'Q4':  {'A': (1858, 1137), 'B': (1947, 1134), 'C': (2036, 1134), 'D': (2129, 1134)},
    'Q5':  {'A': (1855, 1195), 'B': (1947, 1192), 'C': (2036, 1195), 'D': (2129, 1195)},
    'Q6':  {'A': (1855, 1255), 'B': (1947, 1255), 'C': (2036, 1250), 'D': (2129, 1255)},
    'Q7':  {'A': (1853, 1311), 'B': (1947, 1311), 'C': (2036, 1311), 'D': (2129, 1311)},
    'Q8':  {'A': (1859, 1373), 'B': (1947, 1368), 'C': (2036, 1368), 'D': (2129, 1368)},
    'Q9':  {'A': (1853, 1425), 'B': (1947, 1420), 'C': (2036, 1425), 'D': (2129, 1425)},
    'Q10': {'A': (1857, 1482), 'B': (1947, 1477), 'C': (2036, 1482), 'D': (2129, 1482)}
}

section_to_bubbles = {
    'listening': listening_bubbles,
    'structure': structure_bubbles,
    'reading':   reading_bubbles
}

# ==============================
# ALIGNMENT (ORB + HOMOGRAPHY)
# ==============================

orb = cv2.ORB_create(nfeatures=5000)
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

template_kp = None
template_des = None
template_img_resized = None

def load_template_for_alignment(template_path, target_size):
    global template_kp, template_des, template_img_resized
    template_img = cv2.imread(template_path)
    if template_img is None:
        print(f"Error: Could not load template image at {template_path}.")
        raise RuntimeError("Template load failed.")
    template_img_resized = cv2.resize(template_img, target_size)
    gray_template = cv2.cvtColor(template_img_resized, cv2.COLOR_BGR2GRAY)
    template_kp, template_des = orb.detectAndCompute(gray_template, None)
    print("Template loaded and keypoints extracted.")

# ==============================
# DETECTION & GRADING
# ==============================

def detect_answer(gray, options):
    values = {}
    for opt, (x, y) in options.items():
        x_start = max(0, x - RADIUS)
        x_end   = min(gray.shape[1], x + RADIUS)
        y_start = max(0, y - RADIUS)
        y_end   = min(gray.shape[0], y + RADIUS)

        if x_end <= x_start or y_end <= y_start:
            values[opt] = 255
            continue

        roi = gray[y_start:y_end, x_start:x_end]
        values[opt] = np.mean(roi) if roi.size else 255

    sorted_vals = sorted(values.items(), key=lambda v: v[1])

    if len(sorted_vals) > 1:
        darkest_val = sorted_vals[0][1]
        second_val  = sorted_vals[1][1]
        if second_val - darkest_val > CONFIDENCE_GAP:
            return sorted_vals[0][0]

    return None

def grade_section(img, gray_processed, section, key, bubbles):
    correct = 0
    dx, dy = OFFSETS[section]

    for q, options in bubbles.items():
        correct_answer = key.get(q, "0")
        shifted = {opt: (x + dx, y + dy) for opt, (x, y) in options.items()}
        selected = detect_answer(gray_processed, shifted)

        # If this question is disabled / ignored
        if correct_answer == "0":
            for opt, (x, y) in shifted.items():
                color = (200, 200, 200)
                if selected == opt:
                    color = (0, 255, 255)  # yellow-ish for "selected but ignored"
                if 0 <= x < img.shape[1] and 0 <= y < img.shape[0]:
                    cv2.circle(img, (x, y), RADIUS, color, 2)
            continue

        # Normal scoring
        for opt, (x, y) in shifted.items():
            color = (0, 255, 0) if opt == correct_answer else (200, 200, 200)
            if selected == opt:
                if selected == correct_answer:
                    color = (0, 255, 0)    # correct (green)
                else:
                    color = (0, 0, 255)    # incorrect chosen (red)
            if 0 <= x < img.shape[1] and 0 <= y < img.shape[0]:
                cv2.circle(img, (x, y), RADIUS, color, 2)

        if selected == correct_answer:
            correct += 1

    return correct

def draw_score(img, text, pos, font_scale=1.4, thickness=2, color=(0, 0, 0)):
    font = cv2.FONT_HERSHEY_SIMPLEX
    size = cv2.getTextSize(text, font, font_scale, thickness)[0]
    x = pos[0] - size[0] // 2
    y = pos[1] + size[1] // 2
    if 0 <= x < img.shape[1] and 0 <= y < img.shape[0]:
        cv2.putText(img, text, (x, y), font, font_scale, color, thickness)

def grade_image(path, all_scores_list, template_path):
    global template_kp, template_des, template_img_resized

    img = cv2.imread(path)
    if img is None:
        print(f"Error: Could not load image {path}. Skipping.")
        return

    img_resized = cv2.resize(img, TEMPLATE_SIZE)
    gray_img_resized = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)

    kp_img, des_img = orb.detectAndCompute(gray_img_resized, None)

    aligned_img  = img_resized.copy()
    gray_aligned = gray_img_resized.copy()

    if des_img is None or template_des is None:
        print(f"Warning: Not enough keypoints to align {os.path.basename(path)}. Skipping alignment.")
    else:
        matches = bf.match(template_des, des_img)
        matches = sorted(matches, key=lambda x: x.distance)

        num_good_matches = int(len(matches) * 0.15)
        if num_good_matches < 4:
            num_good_matches = min(len(matches), 50)

        good_matches = matches[:num_good_matches]

        if len(good_matches) >= 4:
            src_pts = np.float32([template_kp[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
            dst_pts = np.float32([kp_img[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)
            M, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)

            if M is not None:
                aligned_img  = cv2.warpPerspective(img_resized, M, TEMPLATE_SIZE)
                gray_aligned = cv2.cvtColor(aligned_img, cv2.COLOR_BGR2GRAY)
                print(f"‚úÖ Successfully aligned {os.path.basename(path)}")

                # Save match visualization
                img_matches = cv2.drawMatches(
                    template_img_resized, template_kp,
                    img_resized, kp_img,
                    good_matches, None,
                    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS
                )
                debug_output_path = os.path.join(RESULT_FOLDER, f"{os.path.splitext(os.path.basename(path))[0]}_matches.png")
                cv2.imwrite(debug_output_path, img_matches)
            else:
                print(f"Warning: Homography failed for {os.path.basename(path)}.")
        else:
            print(f"Warning: Too few matches for {os.path.basename(path)}. Skipping alignment.")

    scores = {}
    for section in ['listening', 'structure', 'reading']:
        correct = grade_section(aligned_img, gray_aligned, section, ANSWER_KEY[section], section_to_bubbles[section])
        scores[section] = correct * POINTS[section]

    # Draw section scores
    draw_score(aligned_img, f"{scores['listening']:.1f}/{MAX_POINTS['listening']:.1f}", TEXT_POSITIONS['listening_score_box'])
    draw_score(aligned_img, f"{scores['structure']:.1f}/{MAX_POINTS['structure']:.1f}", TEXT_POSITIONS['structure_score_box'])
    draw_score(aligned_img, f"{scores['reading']:.1f}/{MAX_POINTS['reading']:.1f}",   TEXT_POSITIONS['reading_score_box'])

    filename = os.path.splitext(os.path.basename(path))[0]
    output_image_path = os.path.join(RESULT_FOLDER, f"{filename}_initial_graded.png")
    cv2.imwrite(output_image_path, aligned_img)

    print(f"üìù {filename} graded: L={scores['listening']:.1f}, S={scores['structure']:.1f}, R={scores['reading']:.1f}")

    all_scores_list.append({
        'Student Name': filename,
        'Listening Score (pts)': scores['listening'],
        'Structure Score (pts)': scores['structure'],
        'Reading Score (pts)': scores['reading'],
        'Writing Score (pts)': 0.0,
        'Speaking Score (pts)': 0.0,
        'Platforms Score (pts)': 0.0
    })

def batch_grade(template_path):
    if not os.path.exists(template_path):
        print("\nFATAL: Template file not found. Did you upload it correctly?")
        return

    load_template_for_alignment(template_path, TEMPLATE_SIZE)

    if template_kp is None or template_des is None:
        print("Error: Template features not loaded. Cannot align.")
        return

    all_scores_from_bubble = []

    test_files = [f for f in os.listdir(TEST_FOLDER) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    if not test_files:
        print(f"Warning: No valid images in {TEST_FOLDER}.")
        return

    for f in test_files:
        grade_image(os.path.join(TEST_FOLDER, f), all_scores_from_bubble, template_path)

    if all_scores_from_bubble:
        fieldnames = [
            'Student Name',
            'Listening Score (pts)',
            'Structure Score (pts)',
            'Reading Score (pts)',
            'Writing Score (pts)',
            'Speaking Score (pts)',
            'Platforms Score (pts)'
        ]
        with open(BUBBLE_GRADING_CSV, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_scores_from_bubble)
        print(f"\n‚úÖ CSV saved to: {BUBBLE_GRADING_CSV}")
    else:
        print("\n‚ö†Ô∏è No results to save.")

# ==============================
# MAIN FLOW: UPLOAD / GRADE / DOWNLOAD
# ==============================
print("\n--- 1. Template Upload ---")
print("Please select your Template image (e.g., DEMO2_20250621_0001.png):")
uploaded_template = files.upload()
if not uploaded_template:
    print("Error: No template uploaded. Stopping.")
else:
    TEMPLATE_FILENAME = list(uploaded_template.keys())[0]
    TEMPLATE_PATH = os.path.join(".", TEMPLATE_FILENAME)
    print(f"Template set to: {TEMPLATE_PATH}")

    print("\n--- 2. Test Images Upload ---")
    print("Please select ALL student answer sheet images (PNG/JPG):")
    uploaded_test_files = files.upload()

    if not uploaded_test_files:
        print("Warning: No test files uploaded.")
    else:
        for filename in uploaded_test_files.keys():
            os.rename(filename, os.path.join(TEST_FOLDER, filename))
        print(f"Moved {len(uploaded_test_files)} test images into {TEST_FOLDER}.")

        # Run grading
        try:
            batch_grade(TEMPLATE_PATH)
        except Exception as e:
            print(f"\nError during grading: {e}")

        # --- 3. Download results ---
        print("\n--- 3. Download Results ---")
        if os.path.exists(RESULT_FOLDER) and len(os.listdir(RESULT_FOLDER)) > 0:
            print("Zipping results...")
            try:
                zip_path = shutil.make_archive("graded_results", 'zip', root_dir=".", base_dir=RESULT_FOLDER)
                files.download(zip_path)
                print(f"‚úÖ Download started: {zip_path}")
            except Exception as e:
                print(f"Error while zipping/downloading: {e}")
        else:
            print("‚ö†Ô∏è No results to download.")                  
